{\rtf1\ansi\ansicpg1252\cocoartf1504\cocoasubrtf830
{\fonttbl\f0\fnil\fcharset0 Menlo-Regular;}
{\colortbl;\red255\green255\blue255;\red0\green0\blue0;\red255\green255\blue255;\red255\green255\blue0;
}
{\*\expandedcolortbl;;\csgray\c0;\csgray\c100000;\csgenericrgb\c100000\c100000\c0;
}
\paperw11900\paperh16840\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0

\f0\fs22 \cf2 \cb3 \CocoaLigature0 Mangalas-MBP:~ mangalakhandekar$ cd HadoopPrograms\
Mangalas-MBP:HadoopPrograms mangalakhandekar$ cd WordCountV1     \
Mangalas-MBP:WordCountV1 mangalakhandekar$ javac WordCountV1.java -cp $(hadoop classpath)\
javac: file not found: WordCountV1.java\
Usage: javac <options> <source files>\
use --help for a list of possible options\
Mangalas-MBP:WordCountV1 mangalakhandekar$ javac WordCount.java -cp $(hadoop classpath)\
Mangalas-MBP:WordCountV1 mangalakhandekar$ jar cf WordCount.jar WordCount*.class\
Mangalas-MBP:WordCountV1 mangalakhandekar$ time hadoop jar WordCount.jar WordCount /user/mangalakhandekar/input /user/mangalakhandekar/wcV1Output\
2018-09-18 15:55:16,702 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\
2018-09-18 15:55:17,645 INFO impl.MetricsConfig: loaded properties from hadoop-metrics2.properties\
2018-09-18 15:55:17,764 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).\
2018-09-18 15:55:17,764 INFO impl.MetricsSystemImpl: JobTracker metrics system started\
2018-09-18 15:55:17,937 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.\
2018-09-18 15:55:18,057 INFO input.FileInputFormat: Total input files to process : 4\
2018-09-18 15:55:18,126 INFO mapreduce.JobSubmitter: number of splits:4\
2018-09-18 15:55:18,313 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local1317867103_0001\
2018-09-18 15:55:18,315 INFO mapreduce.JobSubmitter: Executing with tokens: []\
2018-09-18 15:55:18,476 INFO mapreduce.Job: The url to track the job: http://localhost:8080/\
2018-09-18 15:55:18,477 INFO mapreduce.Job: Running job: job_local1317867103_0001\
2018-09-18 15:55:18,478 INFO mapred.LocalJobRunner: OutputCommitter set in config null\
2018-09-18 15:55:18,485 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\
2018-09-18 15:55:18,485 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\
2018-09-18 15:55:18,486 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter\
2018-09-18 15:55:18,533 INFO mapred.LocalJobRunner: Waiting for map tasks\
2018-09-18 15:55:18,534 INFO mapred.LocalJobRunner: Starting task: attempt_local1317867103_0001_m_000000_0\
2018-09-18 15:55:18,557 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\
2018-09-18 15:55:18,558 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\
2018-09-18 15:55:18,569 INFO util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.\
2018-09-18 15:55:18,570 INFO mapred.Task:  Using ResourceCalculatorProcessTree : null\
2018-09-18 15:55:18,573 INFO mapred.MapTask: Processing split: hdfs://localhost:9000/user/mangalakhandekar/input/file2.txt:0+137\
2018-09-18 15:55:18,706 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\
2018-09-18 15:55:18,706 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\
2018-09-18 15:55:18,707 INFO mapred.MapTask: soft limit at 83886080\
2018-09-18 15:55:18,707 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\
2018-09-18 15:55:18,707 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\
2018-09-18 15:55:18,713 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\
2018-09-18 15:55:18,798 INFO mapred.LocalJobRunner: \
2018-09-18 15:55:18,800 INFO mapred.MapTask: Starting flush of map output\
2018-09-18 15:55:18,800 INFO mapred.MapTask: Spilling map output\
2018-09-18 15:55:18,800 INFO mapred.MapTask: bufstart = 0; bufend = 242; bufvoid = 104857600\
2018-09-18 15:55:18,800 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214296(104857184); length = 101/6553600\
2018-09-18 15:55:18,829 INFO mapred.MapTask: Finished spill 0\
2018-09-18 15:55:18,843 INFO mapred.Task: Task:attempt_local1317867103_0001_m_000000_0 is done. And is in the process of committing\
2018-09-18 15:55:18,846 INFO mapred.LocalJobRunner: map\
2018-09-18 15:55:18,846 INFO mapred.Task: Task 'attempt_local1317867103_0001_m_000000_0' done.\
2018-09-18 15:55:18,852 INFO mapred.Task: Final Counters for attempt_local1317867103_0001_m_000000_0: Counters: 23\
	File System Counters\
		FILE: Number of bytes read=3765\
		FILE: Number of bytes written=512329\
		FILE: Number of read operations=0\
		FILE: Number of large read operations=0\
		FILE: Number of write operations=0\
		HDFS: Number of bytes read=137\
		HDFS: Number of bytes written=0\
		HDFS: Number of read operations=5\
		HDFS: Number of large read operations=0\
		HDFS: Number of write operations=1\
	Map-Reduce Framework\
		Map input records=5\
		Map output records=26\
		Map output bytes=242\
		Map output materialized bytes=300\
		Input split bytes=124\
		Combine input records=26\
		Combine output records=26\
		Spilled Records=26\
		Failed Shuffles=0\
		Merged Map outputs=0\
		GC time elapsed (ms)=0\
		Total committed heap usage (bytes)=268435456\
	File Input Format Counters \
		Bytes Read=137\
2018-09-18 15:55:18,852 INFO mapred.LocalJobRunner: Finishing task: attempt_local1317867103_0001_m_000000_0\
2018-09-18 15:55:18,853 INFO mapred.LocalJobRunner: Starting task: attempt_local1317867103_0001_m_000001_0\
2018-09-18 15:55:18,854 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\
2018-09-18 15:55:18,854 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\
2018-09-18 15:55:18,855 INFO util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.\
2018-09-18 15:55:18,855 INFO mapred.Task:  Using ResourceCalculatorProcessTree : null\
2018-09-18 15:55:18,856 INFO mapred.MapTask: Processing split: hdfs://localhost:9000/user/mangalakhandekar/input/file3.txt:0+136\
2018-09-18 15:55:18,883 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\
2018-09-18 15:55:18,883 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\
2018-09-18 15:55:18,884 INFO mapred.MapTask: soft limit at 83886080\
2018-09-18 15:55:18,884 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\
2018-09-18 15:55:18,884 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\
2018-09-18 15:55:18,885 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\
2018-09-18 15:55:18,892 INFO mapred.LocalJobRunner: \
2018-09-18 15:55:18,892 INFO mapred.MapTask: Starting flush of map output\
2018-09-18 15:55:18,892 INFO mapred.MapTask: Spilling map output\
2018-09-18 15:55:18,892 INFO mapred.MapTask: bufstart = 0; bufend = 237; bufvoid = 104857600\
2018-09-18 15:55:18,892 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214300(104857200); length = 97/6553600\
2018-09-18 15:55:18,908 INFO mapred.MapTask: Finished spill 0\
2018-09-18 15:55:18,916 INFO mapred.Task: Task:attempt_local1317867103_0001_m_000001_0 is done. And is in the process of committing\
2018-09-18 15:55:18,921 INFO mapred.LocalJobRunner: map\
2018-09-18 15:55:18,921 INFO mapred.Task: Task 'attempt_local1317867103_0001_m_000001_0' done.\
2018-09-18 15:55:18,922 INFO mapred.Task: Final Counters for attempt_local1317867103_0001_m_000001_0: Counters: 23\
	File System Counters\
		FILE: Number of bytes read=4285\
		FILE: Number of bytes written=512645\
		FILE: Number of read operations=0\
		FILE: Number of large read operations=0\
		FILE: Number of write operations=0\
		HDFS: Number of bytes read=273\
		HDFS: Number of bytes written=0\
		HDFS: Number of read operations=7\
		HDFS: Number of large read operations=0\
		HDFS: Number of write operations=1\
	Map-Reduce Framework\
		Map input records=5\
		Map output records=25\
		Map output bytes=237\
		Map output materialized bytes=284\
		Input split bytes=124\
		Combine input records=25\
		Combine output records=24\
		Spilled Records=24\
		Failed Shuffles=0\
		Merged Map outputs=0\
		GC time elapsed (ms)=7\
		Total committed heap usage (bytes)=268435456\
	File Input Format Counters \
		Bytes Read=136\
2018-09-18 15:55:18,922 INFO mapred.LocalJobRunner: Finishing task: attempt_local1317867103_0001_m_000001_0\
2018-09-18 15:55:18,922 INFO mapred.LocalJobRunner: Starting task: attempt_local1317867103_0001_m_000002_0\
2018-09-18 15:55:18,925 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\
2018-09-18 15:55:18,925 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\
2018-09-18 15:55:18,926 INFO util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.\
2018-09-18 15:55:18,926 INFO mapred.Task:  Using ResourceCalculatorProcessTree : null\
2018-09-18 15:55:18,927 INFO mapred.MapTask: Processing split: hdfs://localhost:9000/user/mangalakhandekar/input/file1.txt:0+123\
2018-09-18 15:55:18,967 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\
2018-09-18 15:55:18,967 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\
2018-09-18 15:55:18,968 INFO mapred.MapTask: soft limit at 83886080\
2018-09-18 15:55:18,968 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\
2018-09-18 15:55:18,968 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\
2018-09-18 15:55:18,969 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\
2018-09-18 15:55:18,975 INFO mapred.LocalJobRunner: \
2018-09-18 15:55:18,975 INFO mapred.MapTask: Starting flush of map output\
2018-09-18 15:55:18,975 INFO mapred.MapTask: Spilling map output\
2018-09-18 15:55:18,976 INFO mapred.MapTask: bufstart = 0; bufend = 208; bufvoid = 104857600\
2018-09-18 15:55:18,976 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214316(104857264); length = 81/6553600\
2018-09-18 15:55:19,000 INFO mapred.MapTask: Finished spill 0\
2018-09-18 15:55:19,014 INFO mapred.Task: Task:attempt_local1317867103_0001_m_000002_0 is done. And is in the process of committing\
2018-09-18 15:55:19,017 INFO mapred.LocalJobRunner: map\
2018-09-18 15:55:19,017 INFO mapred.Task: Task 'attempt_local1317867103_0001_m_000002_0' done.\
2018-09-18 15:55:19,018 INFO mapred.Task: Final Counters for attempt_local1317867103_0001_m_000002_0: Counters: 23\
	File System Counters\
		FILE: Number of bytes read=4805\
		FILE: Number of bytes written=512933\
		FILE: Number of read operations=0\
		FILE: Number of large read operations=0\
		FILE: Number of write operations=0\
		HDFS: Number of bytes read=396\
		HDFS: Number of bytes written=0\
		HDFS: Number of read operations=9\
		HDFS: Number of large read operations=0\
		HDFS: Number of write operations=1\
	Map-Reduce Framework\
		Map input records=5\
		Map output records=21\
		Map output bytes=208\
		Map output materialized bytes=256\
		Input split bytes=124\
		Combine input records=21\
		Combine output records=21\
		Spilled Records=21\
		Failed Shuffles=0\
		Merged Map outputs=0\
		GC time elapsed (ms)=14\
		Total committed heap usage (bytes)=322961408\
	File Input Format Counters \
		Bytes Read=123\
2018-09-18 15:55:19,018 INFO mapred.LocalJobRunner: Finishing task: attempt_local1317867103_0001_m_000002_0\
2018-09-18 15:55:19,018 INFO mapred.LocalJobRunner: Starting task: attempt_local1317867103_0001_m_000003_0\
2018-09-18 15:55:19,019 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\
2018-09-18 15:55:19,019 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\
2018-09-18 15:55:19,020 INFO util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.\
2018-09-18 15:55:19,020 INFO mapred.Task:  Using ResourceCalculatorProcessTree : null\
2018-09-18 15:55:19,022 INFO mapred.MapTask: Processing split: hdfs://localhost:9000/user/mangalakhandekar/input/stop_words.txt:0+29\
2018-09-18 15:55:19,038 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\
2018-09-18 15:55:19,038 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\
2018-09-18 15:55:19,038 INFO mapred.MapTask: soft limit at 83886080\
2018-09-18 15:55:19,038 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\
2018-09-18 15:55:19,038 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\
2018-09-18 15:55:19,039 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\
2018-09-18 15:55:19,056 INFO mapred.LocalJobRunner: \
2018-09-18 15:55:19,056 INFO mapred.MapTask: Starting flush of map output\
2018-09-18 15:55:19,057 INFO mapred.MapTask: Spilling map output\
2018-09-18 15:55:19,057 INFO mapred.MapTask: bufstart = 0; bufend = 70; bufvoid = 104857600\
2018-09-18 15:55:19,057 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214360(104857440); length = 37/6553600\
2018-09-18 15:55:19,086 INFO mapred.MapTask: Finished spill 0\
2018-09-18 15:55:19,095 INFO mapred.Task: Task:attempt_local1317867103_0001_m_000003_0 is done. And is in the process of committing\
2018-09-18 15:55:19,098 INFO mapred.LocalJobRunner: map\
2018-09-18 15:55:19,098 INFO mapred.Task: Task 'attempt_local1317867103_0001_m_000003_0' done.\
2018-09-18 15:55:19,099 INFO mapred.Task: Final Counters for attempt_local1317867103_0001_m_000003_0: Counters: 23\
	File System Counters\
		FILE: Number of bytes read=5325\
		FILE: Number of bytes written=513061\
		FILE: Number of read operations=0\
		FILE: Number of large read operations=0\
		FILE: Number of write operations=0\
		HDFS: Number of bytes read=425\
		HDFS: Number of bytes written=0\
		HDFS: Number of read operations=11\
		HDFS: Number of large read operations=0\
		HDFS: Number of write operations=1\
	Map-Reduce Framework\
		Map input records=10\
		Map output records=10\
		Map output bytes=70\
		Map output materialized bytes=96\
		Input split bytes=129\
		Combine input records=10\
		Combine output records=10\
		Spilled Records=10\
		Failed Shuffles=0\
		Merged Map outputs=0\
		GC time elapsed (ms)=7\
		Total committed heap usage (bytes)=322961408\
	File Input Format Counters \
		Bytes Read=29\
2018-09-18 15:55:19,099 INFO mapred.LocalJobRunner: Finishing task: attempt_local1317867103_0001_m_000003_0\
2018-09-18 15:55:19,099 INFO mapred.LocalJobRunner: map task executor complete.\
2018-09-18 15:55:19,102 INFO mapred.LocalJobRunner: Waiting for reduce tasks\
2018-09-18 15:55:19,102 INFO mapred.LocalJobRunner: Starting task: attempt_local1317867103_0001_r_000000_0\
2018-09-18 15:55:19,110 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\
2018-09-18 15:55:19,110 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\
2018-09-18 15:55:19,111 INFO util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.\
2018-09-18 15:55:19,111 INFO mapred.Task:  Using ResourceCalculatorProcessTree : null\
2018-09-18 15:55:19,114 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2d2dd5d7\
2018-09-18 15:55:19,116 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!\
2018-09-18 15:55:19,138 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=3006477056, maxSingleShuffleLimit=751619264, mergeThreshold=1984274944, ioSortFactor=10, memToMemMergeOutputsThreshold=10\
2018-09-18 15:55:19,140 INFO reduce.EventFetcher: attempt_local1317867103_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\
2018-09-18 15:55:19,169 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1317867103_0001_m_000001_0 decomp: 280 len: 284 to MEMORY\
2018-09-18 15:55:19,171 INFO reduce.InMemoryMapOutput: Read 280 bytes from map-output for attempt_local1317867103_0001_m_000001_0\
2018-09-18 15:55:19,173 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 280, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->280\
2018-09-18 15:55:19,175 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1317867103_0001_m_000003_0 decomp: 92 len: 96 to MEMORY\
2018-09-18 15:55:19,176 INFO reduce.InMemoryMapOutput: Read 92 bytes from map-output for attempt_local1317867103_0001_m_000003_0\
2018-09-18 15:55:19,176 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 92, inMemoryMapOutputs.size() -> 2, commitMemory -> 280, usedMemory ->372\
2018-09-18 15:55:19,178 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1317867103_0001_m_000000_0 decomp: 296 len: 300 to MEMORY\
2018-09-18 15:55:19,179 INFO reduce.InMemoryMapOutput: Read 296 bytes from map-output for attempt_local1317867103_0001_m_000000_0\
2018-09-18 15:55:19,179 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 296, inMemoryMapOutputs.size() -> 3, commitMemory -> 372, usedMemory ->668\
2018-09-18 15:55:19,180 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1317867103_0001_m_000002_0 decomp: 252 len: 256 to MEMORY\
2018-09-18 15:55:19,182 INFO reduce.InMemoryMapOutput: Read 252 bytes from map-output for attempt_local1317867103_0001_m_000002_0\
2018-09-18 15:55:19,182 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 252, inMemoryMapOutputs.size() -> 4, commitMemory -> 668, usedMemory ->920\
2018-09-18 15:55:19,182 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning\
2018-09-18 15:55:19,183 INFO mapred.LocalJobRunner: 4 / 4 copied.\
2018-09-18 15:55:19,183 INFO reduce.MergeManagerImpl: finalMerge called with 4 in-memory map-outputs and 0 on-disk map-outputs\
2018-09-18 15:55:19,198 INFO mapred.Merger: Merging 4 sorted segments\
2018-09-18 15:55:19,199 INFO mapred.Merger: Down to the last merge-pass, with 4 segments left of total size: 903 bytes\
2018-09-18 15:55:19,206 INFO reduce.MergeManagerImpl: Merged 4 segments, 920 bytes to disk to satisfy reduce memory limit\
2018-09-18 15:55:19,207 INFO reduce.MergeManagerImpl: Merging 1 files, 918 bytes from disk\
2018-09-18 15:55:19,208 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce\
2018-09-18 15:55:19,208 INFO mapred.Merger: Merging 1 sorted segments\
2018-09-18 15:55:19,208 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 910 bytes\
2018-09-18 15:55:19,208 INFO mapred.LocalJobRunner: 4 / 4 copied.\
2018-09-18 15:55:19,259 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords\
2018-09-18 15:55:19,342 INFO mapred.Task: Task:attempt_local1317867103_0001_r_000000_0 is done. And is in the process of committing\
2018-09-18 15:55:19,344 INFO mapred.LocalJobRunner: 4 / 4 copied.\
2018-09-18 15:55:19,344 INFO mapred.Task: Task attempt_local1317867103_0001_r_000000_0 is allowed to commit now\
2018-09-18 15:55:19,365 INFO output.FileOutputCommitter: Saved output of task 'attempt_local1317867103_0001_r_000000_0' to hdfs://localhost:9000/user/mangalakhandekar/wcV1Output\
2018-09-18 15:55:19,367 INFO mapred.LocalJobRunner: reduce > reduce\
2018-09-18 15:55:19,367 INFO mapred.Task: Task 'attempt_local1317867103_0001_r_000000_0' done.\
2018-09-18 15:55:19,367 INFO mapred.Task: Final Counters for attempt_local1317867103_0001_r_000000_0: Counters: 29\
	File System Counters\
		FILE: Number of bytes read=7307\
		FILE: Number of bytes written=513979\
		FILE: Number of read operations=0\
		FILE: Number of large read operations=0\
		FILE: Number of write operations=0\
		HDFS: Number of bytes read=425\
		HDFS: Number of bytes written=476\
		HDFS: Number of read operations=16\
		HDFS: Number of large read operations=0\
		HDFS: Number of write operations=3\
	Map-Reduce Framework\
		Combine input records=0\
		Combine output records=0\
		Reduce input groups=63\
		Reduce shuffle bytes=936\
		Reduce input records=81\
		Reduce output records=63\
		Spilled Records=81\
		Shuffled Maps =4\
		Failed Shuffles=0\
		Merged Map outputs=4\
		GC time elapsed (ms)=0\
		Total committed heap usage (bytes)=322961408\
	Shuffle Errors\
		BAD_ID=0\
		CONNECTION=0\
		IO_ERROR=0\
		WRONG_LENGTH=0\
		WRONG_MAP=0\
		WRONG_REDUCE=0\
	File Output Format Counters \
		Bytes Written=476\
2018-09-18 15:55:19,368 INFO mapred.LocalJobRunner: Finishing task: attempt_local1317867103_0001_r_000000_0\
2018-09-18 15:55:19,368 INFO mapred.LocalJobRunner: reduce task executor complete.\
2018-09-18 15:55:19,489 INFO mapreduce.Job: Job job_local1317867103_0001 running in uber mode : false\
2018-09-18 15:55:19,490 INFO mapreduce.Job:  map 100% reduce 100%\
2018-09-18 15:55:19,491 INFO mapreduce.Job: Job job_local1317867103_0001 completed successfully\
2018-09-18 15:55:19,502 INFO mapreduce.Job: Counters: 35\
	File System Counters\
		FILE: Number of bytes read=25487\
		FILE: Number of bytes written=2564947\
		FILE: Number of read operations=0\
		FILE: Number of large read operations=0\
		FILE: Number of write operations=0\
		HDFS: Number of bytes read=1656\
		HDFS: Number of bytes written=476\
		HDFS: Number of read operations=48\
		HDFS: Number of large read operations=0\
		HDFS: Number of write operations=7\
	Map-Reduce Framework\
		Map input records=25\
		Map output records=82\
		Map output bytes=757\
		Map output materialized bytes=936\
		Input split bytes=501\
		Combine input records=82\
		Combine output records=81\
		Reduce input groups=63\
		Reduce shuffle bytes=936\
		Reduce input records=81\
		Reduce output records=63\
		Spilled Records=162\
		Shuffled Maps =4\
		Failed Shuffles=0\
		Merged Map outputs=4\
		GC time elapsed (ms)=28\
		Total committed heap usage (bytes)=1505755136\
	Shuffle Errors\
		BAD_ID=0\
		CONNECTION=0\
		IO_ERROR=0\
		WRONG_LENGTH=0\
		WRONG_MAP=0\
		WRONG_REDUCE=0\
	File Input Format Counters \
		Bytes Read=425\
	File Output Format Counters \
		Bytes Written=476\
\
\cb4 real	0m3.926s\
user	0m9.720s\
sys	0m0.653s\cb3 \
Mangalas-MBP:WordCountV1 mangalakhandekar$ hadoop fs -cat /user/mangalakhandekar/wcV1Output/part-r-00000\
2018-09-18 15:57:37,685 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\
,	1\
.	1\
A	2\
An	2\
And	1\
Are	1\
Because,	1\
But	1\
Elephant	1\
HDFS	1\
Hadoop	2\
Hadoop.	1\
He	2\
Hive,	1\
Impala,	1\
King!	1\
Or	1\
Sqoop.	1\
The	1\
Useful	1\
a	1\
an	2\
and	4\
anything	1\
at	1\
bad,	1\
but	1\
cling!	1\
core,	1\
data,	1\
does	1\
elegant	2\
element	1\
elephant	2\
extraneous	1\
fellow.	1\
forgets	1\
gentle	1\
gets	1\
group.	1\
he	1\
helps	1\
him	1\
his	1\
in	1\
is	5\
king	1\
lets	1\
mad,	1\
mellow.	1\
never	2\
or	2\
plays	1\
the	3\
thing.	1\
thrive	1\
to	2\
well	1\
what	1\
with	1\
wonderful	1\
yellow	1\
yellow.	1\
Mangalas-MBP:WordCountV1 mangalakhandekar$ \
}